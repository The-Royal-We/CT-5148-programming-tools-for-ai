{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=img/MScAI_brand.png width=70%></center>\n",
    "\n",
    "# Measuring Object Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have discussed computational complexity, and argued that both time complexity and space complexity are really the same concept, applied to two different quantities - number of instructions executed during runtime, and amount of space used during runtime.\n",
    "\n",
    "But complexity is a term which has a lot of meanings in maths, physics, and AI. An important meaning in AI is: how complex is an object? Notice this is not closely related to computational complexity.\n",
    "\n",
    "Another way of saying the same thing is: **how much information** is there in the object.\n",
    "\n",
    "In this notebook we'll briefly look at this idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Focus on strings\n",
    "\n",
    "* We are not necessarily talking about objects in the OOP sense, but rather data structures in general. \n",
    "\n",
    "* Usually, we just focus on strings, because every computational object can be converted to a string somehow. \n",
    "\n",
    "* If we were talking about physical objects (eg, complexity of Notre Dame cathedral versus complexity of a barn) or even about other types of information (eg complexity of a piece of music by Beethoven, versus a nursery rhyme), we could still do it by somehow encoding a complete description of the object as a string. So, we focus on strings from now on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples\n",
    "\n",
    "Consider the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'aaaaaaaaaaaaaaaaaaaaaaaa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The pattern in this string is very obvious! Even though there are 24 characters, we might say there is not much complexity, not much information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now consider another string (drawn from the same alphabet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = 'abcdabcdabcdabcdabcdabcd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This time, there is more complexity, but still a very obvious pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now consider a third string. It doesn't seem that there is any pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = 'abaabddbcbabdbabcccadacc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We might say:\n",
    "\n",
    "`s1` contains the least information (lowest complexity), `s2` is in the middle (medium complexity), and `s3` contains the most (highest complexity).\n",
    "\n",
    "```\n",
    "s1 = 'aaaaaaaaaaaaaaaaaaaaaaaa'\n",
    "s2 = 'abcdabcdabcdabcdabcdabcd'\n",
    "s3 = 'abaabddbcbabdbabcccadacc'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Measuring complexity\n",
    "\n",
    "How can we quantify what we have observed?\n",
    "\n",
    "One method is to calculate the **number of distinct $n$-grams**. \n",
    "\n",
    "If there are just a few $n$-grams in the string, it proves there must be a lot of repetition. If there are many distinct ones, it proves there is less repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def count_distinct_ngrams(s, n):\n",
    "    ngrams = [s[i:i+n] for i in range(len(s) - n + 1)]\n",
    "    # print(len(ngrams), ngrams)\n",
    "    return len(set(ngrams)) # count distinct ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaaaaaaaaaaaaaaa: 1\n",
      "abcdabcdabcdabcdabcdabcd: 4\n",
      "abaabddbcbabdbabcccadacc: 21\n"
     ]
    }
   ],
   "source": [
    "for s in (s1, s2, s3):\n",
    "    print(f'{s}: {count_distinct_ngrams(s, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This seems to be giving the right idea: it tells us the first string is extremely simple and the last is more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Kolmogorov complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our $n$-gram method works ok for a lot of cases, but it's not the only method.\n",
    "\n",
    "Another method is based on the observation: if we can **compress** the string, it proves we have identified there is pattern in it. More pattern implies less complexity (less information). \n",
    "\n",
    "For example, consider again: `s2 = 'abcdabcdabcdabcdabcdabcd'`. We can write a shorter string which is equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdabcdabcdabcdabcdabcd'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'abcd' * 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This can be much very powerful. For some strings our $n$-grams method will give a high value, even though the human eye can see there is a pattern. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = '112123123412345123456123456712345678'\n",
    "count_distinct_ngrams(s4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Probably we could compress `s4` by **writing a short program** which outputs `s4`. (**Exercise**: try it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Based on this, we define the **Kolmogorov complexity** for a string $s$: **the length of the shortest program which would output $s$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unfortunately, finding the **shortest program which outputs a given string** is **uncomputable**: no algorithm can guarantee to do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Some other practical methods\n",
    "\n",
    "So, in practice we use simple methods, eg:\n",
    "\n",
    "* Our method, counting distinct $n$-grams\n",
    "* Entropy (are all symbols equally common in the string?)\n",
    "* Conditional entropy (are all $n$-grams equally common in the string?)\n",
    "* LZW-compression (related to the algorithms used in zip compression, see eg https://rosettacode.org/wiki/LZW_compression#Python)\n",
    "* Assembly (how many \"joins\" do we need to do to assemble the string from single letters, allowing for reuse of substrings?).\n",
    "* More generally, the field of **Algorithmic Information Theory** is about these kinds of concepts.\n",
    "\n",
    "If you would like to see some of these, read on. These are not examinable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "from itertools import product\n",
    "from sksequitur import parse # pip install scikit-sequitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaaaaaaaaaaaaaaa: 0.651\n",
      "abcdabcdabcdabcdabcdabcd: 5.182\n",
      "abaabddbcbabdbabcccadacc: 31.173\n"
     ]
    }
   ],
   "source": [
    "def condent(s, n=2, alphabet=None, k=1):\n",
    "    '''\n",
    "    Conditional entropy\n",
    "    Using n-grams as the \"predictors\"\n",
    "    Using optional smoothing\n",
    "    Using optional specification of a larger alphabet\n",
    "    '''\n",
    "\n",
    "    # Initialise alphabet if not specified and check\n",
    "    if alphabet == None:\n",
    "        alphabet = sorted(''.join(set(s)))\n",
    "    assert all((x in alphabet for x in s))\n",
    "\n",
    "    # Initialize smoothed counts for single symbols and n-grams\n",
    "    # ie create a value of k for every possible single symbol\n",
    "    # and every possible (n-1)-gram and every possible n-gram\n",
    "    single_freqs = {symbol: k for symbol in alphabet}\n",
    "    ngram_freqs = {''.join(gram): k for gram in product(alphabet, repeat=n)}\n",
    "    n_1_gram_freqs = {''.join(gram): k for gram in product(alphabet, repeat=n-1)}\n",
    "    \n",
    "    # Count n-gram frequencies, updating smoothed counts\n",
    "    for i in range(len(s) - n + 1):\n",
    "        ngram = s[i:i + n]\n",
    "        if ngram in ngram_freqs:\n",
    "            ngram_freqs[ngram] += 1\n",
    "\n",
    "    # Count (n-1)-gram frequencies, updating smoothed counts\n",
    "    for i in range(len(s) - n + 2):\n",
    "        n_1_gram = s[i:i + n - 1]\n",
    "        if n_1_gram in n_1_gram_freqs:\n",
    "            n_1_gram_freqs[n_1_gram] += 1\n",
    "\n",
    "    # Calculate conditional probabilities based on smoothed counts\n",
    "    cond_prob = {ngram: count / n_1_gram_freqs[ngram[:-1]] for ngram, count in ngram_freqs.items()}\n",
    "    \n",
    "    # Calculate conditional entropy\n",
    "    entropy = -sum(prob * log2(prob) for prob in cond_prob.values())\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "for s in (s1, s2, s3):\n",
    "    print(f'{s}: {condent(s, n=4, alphabet=\"abcd\"):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaaaaaaaaaaaaaaa: 5\n",
      "abcdabcdabcdabcdabcdabcd: 6\n",
      "abaabddbcbabdbabcccadacc: 18\n"
     ]
    }
   ],
   "source": [
    "def assembly_index(s):\n",
    "    '''\n",
    "    Assembly index as defined by Cronin and colleagues\n",
    "    g is a \"grammar\"\n",
    "\n",
    "    eg for s = 'abcabcabc', we get a grammar of two rewrite rules:\n",
    "    0 -> 1 1 1\n",
    "    1 -> a b c \n",
    "\n",
    "    Each rule of length k require (k-1) joins \n",
    "    (eg '1 1 1' requires 2 joins)\n",
    "    hence our formula summing len(g[k]) - 1\n",
    "    '''\n",
    "    g = parse(s) \n",
    "    # each rule in the grammar\n",
    "    return sum(len(g[k]) - 1 for k in g)\n",
    "\n",
    "\n",
    "for s in (s1, s2, s3):\n",
    "    print(f'{s}: {assembly_index(s)}')\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
